---
title: "INTRODUÇÃO AO PYTHON"
author: "João Ricardo F. de Lima"
date: "today"
editor: source
lang: pt
language: 
  toc-title-document: '<a href="https://www.facape.br/" target="_blank"><img src="https://github.com/econfacape/macroeconometria/blob/main/logofacape.jpg?raw=true" alt="Logotipo Facape" width="150"></a>'
format: 
  html:
    toc: true
    toc_float:
      collapsed: yes
      smooth_scroll: yes
    toc-location: left
    code-fold: false
    embed-resources: true
    page-layout: full
    fig-asp: 0.618
    fig-width: 8
    fig-height: 5
    fig-dpi: 300
    fig-align: center
    df-print: paged
    fontsize: 13pt
theme:
  light: flatly
execute:
  echo: TRUE
  message: false
  warning: false
#jupyter: python3
---

## Introdução

<br>

[^1]Há duas principais maneiras de chegar a esse ambiente de programação:

- **Localmente**: é preciso instalar o Python e uma IDE no seu computador.

- **Na nuvem**: acessa pelo navegador um ambiente já pronto e configurado para rodar Python.

[^1]: Todo este material foi retirado de diversas postagens e cursos da Análise Macro (www.analisemacro.com.br)

Um ambiente na nuvem pode ser o `Jupyter Notebook/Google Colab` e um ambiente local pode ser o `VsCode` ou `Anaconda`, mas a opção aqui é o Quarto do RStudio.

<br>

### Jupyter Notebook/Google Colab

O Jupyter Notebook é uma interface para programar em uma estrutura de "caderno de anotação": você pode escrever textos, inserir imagens, etc. e adicionar blocos de código, assim como exibir os resultados do código, tudo em um mesmo arquivo. Suas principais vantagens se referem a interface simples e intuitiva para iniciantes, além da facilidade de compartilhar códigos.

Para usar a interface do Jupyter na nuvem, basta seguir estes passos:

1. Ter uma conta no [Google](https://www.google.com.br/);
2. Acessar o [Google Drive](https://drive.google.com/);
3. Clicar em Novo (*New*) > Mais (*More*) > Google Colaboratory.

E com isso já se tem um ambiente de programação em Python. 

O que estes procedimentos fazem é criar um arquivo "*Untitled0.ipynb*" no seu Google Drive. Dessa forma, você pode escolher onde criar o arquivo e organizar seus códigos em pastas, se preferir.

O ponto forte está na sua capacidade de fácil integração (Google Drive, Github, entre outros), além de não ser necessário ter instalado a linguagem na máquina.

Para acessar, basta ir no site https://colab.research.google.com/, ter uma conta Google e criar um novo notebook.

<br>

### Quarto

O uso no Quarto se torna mais tranquilo para quem já usa o RStudio e trabalha tanto com o R quanto o Python. Para inserir os códigos a única diferença é que os `chunks` passam agora a iniciar com `{python}` ao invés de `{r}` depois das três crases. 

E ainda existe a possibilidade de rodar Python dentro do R, desde que seja usado o pacote `reticulate`. 

Um bom post sobre como preparar o ambiente de trabalho deve ser lido nesta página (https://analisemacro.com.br/data-science/python/introducao-ao-python-como-preparar-o-ambiente-de-trabalho/).

```{r}
#install.packages("reticulate")
reticulate::py_config()
```

```{python}
#py -m pip install jupyter
1 + 1
```

<br>

# Instalações de Pacotes

```{r}
#reticulate::py_install("pandas")
```

```{python, eval=FALSE}
#!pip install python-bcb #Google Colab
#py -m pip install python-bcb #Terminal Windows
#python3 -m pip install python-bcb #Terminal Mac
```

<br>

# Pacotes pandas e numpy

::: grid
::: g-col-6
### **Pandas**

- É uma biblioteca para **análise e tratamento de dados** no Python.<br><br>
- Oferece uma **sintaxe** e **estrutura de dados** flexível.<br><br>
- Cobre (quase) tudo que você precisa para **analisar dados**.<br><br>
- É **gratuito** e de **código aberto**.

Saiba mais: [https://pandas.pydata.org/](https://pandas.pydata.org/)

:::

::: g-col-6
### **Numpy**

- É uma biblioteca para **computação numérica** no Python;<br><br>
- Oferece uma **estrutura vetorial e matricial** para dados numéricos;<br><br>
- É a **base de muitas bibliotecas**;<br><br>
- É **gratuito** e de **código aberto**.

Saiba mais: [https://numpy.org/](https://numpy.org/)

:::
:::

<br>

## Unboxing do pandas

::: grid
::: g-col-6
<br>

### Estrutura de dados tabulares
```{r, echo=FALSE, out.width="45%"}
knitr::include_graphics("imgs/pd_dataframe.svg")
```

:::
::: g-col-6

### Leitura e escrita de arquivos *offline*
```{r, echo=FALSE, out.width="95%"}
knitr::include_graphics("imgs/pd_import_export.svg")
```

:::
:::


::: grid
::: g-col-6

###  Manipulação de dados facilitada
```{r, echo=FALSE, out.width="85%"}
knitr::include_graphics("imgs/pd_wrangle.svg")
```

:::
::: g-col-6

###  Módulo para visualização de dados
```{r, echo=FALSE, out.width="95%"}
knitr::include_graphics("imgs/pd_dataviz.svg")
```

:::
:::

## Para fazer isso:

O ciclo de análise de dados...

```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("imgs/ciclo_dados.png")
```

<br>

## Com o pandas, numpy e o Python, usa-se isso:

As principais bibliotecas usados para análise de dados.

```{r, echo=FALSE, out.width="100%"}
knitr::include_graphics("imgs/ciclo_dados_bibliotecas.png")
```

<br>

## Importando Arquivos

Para importar um arquivo CSV *offline* pode-se usar a biblioteca `pandas` no Python:

```{python, message=TRUE, warning=TRUE}
# Importa o arquivo "dados.csv" salvo na pasta "dados" a partir da pasta atual
import pandas as pd
tabela = pd.read_csv(filepath_or_buffer = "dados/dados.csv")
```

A função `read_csv()` importa o arquivo para um objeto `DataFrame` no Python, basta apontar a localização.

Por padrão, a função tenta adivinhar os tipos das colunas e utiliza a primeira linha como nome das colunas da tabela.

```{python}
tabela
```

<br>

### Importando CSV com ponto e vírgula (;) de separador

O padrão de arquivos CSV é usar a vírgula como separador dos valores, mas em alguns casos o arquivo CSV pode ter sido gerado com um separador diferente.

No caso de separador ponto e vírgula (;) em um arquivo CSV, o padrão é que os decimais sejam, então, uma vírgula. Para importar nesse formato use os argumentos da função `read_csv()`:

```{python}
# Importa arquivo CSV com separador ;
tabela = pd.read_csv(filepath_or_buffer = "dados/dados_pv.csv", 
        sep = ";", decimal = ",")
tabela.head()
```

<br>

### Lidando com codificação de caracteres

O padrão do pacote `pandas` é utilizar a mesma codificação de caracteres de fábrica do Python, que é a UTF-8. Se o arquivo CSV foi gerado com outra codificação pode ser que a importação dos dados saia do resultado desejado. O principal problema que pode acontecer é caracteres especiais, como "ç", não serem reconhecidos ou a importação gerar um erro. Por exemplo (dados do TSE):

```{python, error=TRUE}
# Importa arquivo CSV com separador ; e encoding padrão (gera um erro)
tse_codificacao_eua = pd.read_csv(
  filepath_or_buffer = "dados/tse.csv", 
  sep = ";"
  )
```

Para lidar com esses problemas deve-se apontar uma codificação compatível com o arquivo no momento da importação. Basta informar no argumento `encoding` qual é a codificação correta:

```{python}
# Importa arquivo CSV com separador ; e encoding latin1
tse_codificacao_br = pd.read_csv(
  filepath_or_buffer = "dados/tse.csv",
  sep = ";",
  encoding = "latin_1"
  )
tse_codificacao_br.iloc[range(3), range(6)]
```

<br>

### Importando Excel

Para importar um arquivo Excel *offline* também pode usar a biblioteca **pandas** no Python:

```{python, message=TRUE, warning=TRUE}
import pandas as pd
tabela_excel = pd.read_excel(io = "dados/dados.xlsx")
tabela_excel
```

<br>

### Importando determinada Planilha do arquivo Excel

Para importar uma *sheet* específica do arquivo Excel no Python basta apontar o nome ou um *int* com sua posição (índice começa no 0):
  
```{python}
tabela_ibcbr1 = pd.read_excel(
  io = "dados/dados.xlsx", 
  sheet_name = "ibc_br"
  )
tabela_ibcbr1
```


```{python}
tabela_ibcbr2 = pd.read_excel(
  io = "dados/dados.xlsx", 
  sheet_name = 1
)
tabela_ibcbr2
```

<br>

### Importação de Dados de Bases Brasileiras

- Dados do **BCB** - utilizando a biblioteca `python-bcb`
- Dados do **IPEADATA** - utilizando a biblioteca `ipeadatapy`
- Dados do **Sidra/IBGE** - - utilizando a biblioteca `sidrapy`
 
<br> 
Com uma série no Banco Central:
  
```{python}
# Coletar dados da SELIC no SGS/BCB
from bcb import sgs # nome da biblioteca é "bcb"
dados_sgs = sgs.get(codes = 432, start = "2020-01-01")
dados_sgs
```

<br>

Com múltiplas séries:
  
```{python}
dados_sgs = sgs.get(
  codes = {"Dólar": 3698, "IBC-Br": 24363, "Resultado Primário": 5793},
  start = "2020-01-01"
)
dados_sgs.tail()
```

<br>

Para coletar os dados do Sistema de Expectativas:
  
- **Passo 1**: localize no site [https://olinda.bcb.gov.br/olinda/servico/Expectativas/versao/v1/aplicacao#!/recursos](https://olinda.bcb.gov.br/olinda/servico/Expectativas/versao/v1/aplicacao#!/recursos) uma das bases de dados (*endpoint*) disponíveis;

- **Passo 2**: preencha na tela os filtros para a consulta de dados (veja [essa página](https://olinda.bcb.gov.br/olinda/servico/ajuda) de ajuda);

- **Passo 3**: selecione o formato de saída *text/csv* e clique em *Copiar URL*.

- **Passo 4**: utilize a biblioteca `pandas` para importar os dados.

<br>

```{python}
# Coleta de dados de Expectativas de Mercado para Câmbio - final do ano

import pandas as pd

dados_focus = pd.read_csv(
        filepath_or_buffer = "https://olinda.bcb.gov.br/olinda/servico/Expectativas/versao/v1/odata/ExpectativasMercadoAnuais?$top=100&$filter=Indicador%20eq%20'C%C3%A2mbio'%20and%20Data%20ge%20'2024-01-01'%20and%20DataReferencia%20eq%20'2024'%20and%20baseCalculo%20gt%200&$format=text/csv&$select=Indicador,Data,DataReferencia,Media,baseCalculo",
    decimal = ",",
    sep = ",",
    encoding = "latin_1"
)
dados_focus
```
              
Em relação aos dados do IPEADATA, suponha que o objetivo seja coletar a série do saldo do Novo CAGED. 

- **Passo 1**: utilize a função `list_series()` para localizar a série desejada e obter o código da mesma (retorna um `DataFrame`);

```{python}
# Extrair tabela com todas séries e códigos disponíveis
import ipeadatapy as ipea
series_ipeadata = ipea.list_series()

# Filtrar séries com o termo "CAGED"
series_ipeadata[series_ipeadata.CODE.str.contains("CAGED")]
```

- **Passo 2**: aponte na função `timeseries()` o código da séries de interesse:

```{python}
dados_ipeadata = ipea.timeseries(series = "CAGED12_SALDON12")
dados_ipeadata.head()
dados_ipeadata.tail()
```

Dessa forma simples se tem acesso rápido e fácil a diversas séries. Importante consultar os detalhes dos argumentos na documentação da biblioteca e, sobre as séries, pela função `metadata()` ou no site da instituição.

No caso dos dados do SIDRA, o mais fácil é consultar no SIDRA, obter o link e importar com o `pandas`. 

- **Passo 1**: localize no site [https://sidra.ibge.gov.br/](https://sidra.ibge.gov.br/) a tabela de interesse e aplique os filtros desejados (neste caso marcamos "Variável" = "'Area Colhida"; "Produto das lavouras temporárias e permanentes" = "Manga"; "Ano" = 2003 a 2022 e "Unidade Territorial" = "Sao Francisco Pernambucano e Vale Sao Franciscano da Bahia");
- **Passo 2**: clique no botão de compartilhar, na parte inferior, chamado “Links de compartilhar” e no primeiro campo na tela que se abre, "Parâmetros para a API", copie o link que aparece;
- **Passo 3**: utilize a função `read_json()` do `pandas` para importar os dados, adicionando ao final do link esta opção "*?formato=json*".

Dessa forma simples conseguimos acesso rápido e fácil aos dados de qualquer tabela do Sidra. Consulte os detalhes e mais opções na documentação das bibliotecas e, sobre as tabelas, no site da instituição.


```{python}
# Importar tabela 5457 do Sidra/IBGE
import pandas as pd
dados_sidra = pd.read_json(
  path_or_buf = "https://apisidra.ibge.gov.br/values/t/5457/n8/2602,2902/v/216/p/last%2020/c782/0?formato=json"
  )
dados_sidra.tail()
```

